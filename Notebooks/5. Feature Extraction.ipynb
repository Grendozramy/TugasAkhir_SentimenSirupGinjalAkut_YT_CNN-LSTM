{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "from ast import literal_eval\n",
    "\n",
    "# Gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset : 4776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_removal</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_manual_replaced</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video1</td>\n",
       "      <td>Baiknya bagaimana menurut kalian?</td>\n",
       "      <td>baiknya bagaimana menurut kalian</td>\n",
       "      <td>baik bagaimana turut kalian</td>\n",
       "      <td>baik bagaimana turut kalian</td>\n",
       "      <td>baik bagaimana turut kalian</td>\n",
       "      <td>[baik, bagaimana, turut, kalian]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video1</td>\n",
       "      <td>Betul dok betul  dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>[betul, dok, betul, dok]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video1</td>\n",
       "      <td>Betul dok mungkin efek sa di</td>\n",
       "      <td>betul dok mungkin efek sa di</td>\n",
       "      <td>betul dok mungkin efek sa</td>\n",
       "      <td>betul dok mungkin efek sa</td>\n",
       "      <td>betul dok mungkin efek sa</td>\n",
       "      <td>[betul, dok, mungkin, efek, sa]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video1</td>\n",
       "      <td>Bpom aneh, tidak kerja. Kenapa ko seperti itu.</td>\n",
       "      <td>bpom aneh tidak kerja kenapa ko seperti itu</td>\n",
       "      <td>bpom aneh kerja ko itu</td>\n",
       "      <td>bpom aneh kerja kok itu</td>\n",
       "      <td>bpom aneh kerja kok itu</td>\n",
       "      <td>[bpom, aneh, kerja, kok, itu]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video1</td>\n",
       "      <td>Benar banget anak sy aj hrs sirup minum obatny...</td>\n",
       "      <td>benar banget anak sy aj hrs sirup minum obatny...</td>\n",
       "      <td>benar banget anak sy aj hrs sirup minum obat d...</td>\n",
       "      <td>benar banget anak saya saja harus sirup minum ...</td>\n",
       "      <td>benar banget anak aku saja harus sirup minum o...</td>\n",
       "      <td>[benar, banget, anak, aku, saja, harus, sirup,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id                                       comment_text  \\\n",
       "0   video1                  Baiknya bagaimana menurut kalian?   \n",
       "1   video1                               Betul dok betul  dok   \n",
       "2   video1                       Betul dok mungkin efek sa di   \n",
       "3   video1     Bpom aneh, tidak kerja. Kenapa ko seperti itu.   \n",
       "4   video1  Benar banget anak sy aj hrs sirup minum obatny...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0                   baiknya bagaimana menurut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                       betul dok mungkin efek sa di   \n",
       "3        bpom aneh tidak kerja kenapa ko seperti itu   \n",
       "4  benar banget anak sy aj hrs sirup minum obatny...   \n",
       "\n",
       "                                        text_removal  \\\n",
       "0                        baik bagaimana turut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                          betul dok mungkin efek sa   \n",
       "3                             bpom aneh kerja ko itu   \n",
       "4  benar banget anak sy aj hrs sirup minum obat d...   \n",
       "\n",
       "                                     text_normalized  \\\n",
       "0                        baik bagaimana turut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                          betul dok mungkin efek sa   \n",
       "3                            bpom aneh kerja kok itu   \n",
       "4  benar banget anak saya saja harus sirup minum ...   \n",
       "\n",
       "                                text_manual_replaced  \\\n",
       "0                        baik bagaimana turut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                          betul dok mungkin efek sa   \n",
       "3                            bpom aneh kerja kok itu   \n",
       "4  benar banget anak aku saja harus sirup minum o...   \n",
       "\n",
       "                                       text_tokenize  label  \n",
       "0                   [baik, bagaimana, turut, kalian]      0  \n",
       "1                           [betul, dok, betul, dok]      0  \n",
       "2                    [betul, dok, mungkin, efek, sa]      0  \n",
       "3                      [bpom, aneh, kerja, kok, itu]     -1  \n",
       "4  [benar, banget, anak, aku, saja, harus, sirup,...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('../Data/4. Labeling/labeling.csv')\n",
    "\n",
    "# Mengonversi kolom tokenisasi menjadi list\n",
    "df['text_tokenize'] = df['text_tokenize'].apply(literal_eval)\n",
    "\n",
    "text_tokenize = df['text_tokenize']\n",
    "\n",
    "# Menampilkan total dataset\n",
    "print(\"Total Dataset :\", len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec dengan arsitektur Continuous Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 1595412.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Jumlah core CPU yang tersedia: memeriksa jumlah core CPU untuk paralelisasi\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Membuat model Word2Vec dengan arsitektur CBOW: mengatur parameter untuk model Word2Vec\n",
    "model_ug_cbow = Word2Vec(\n",
    "    sg=0,  # Menggunakan CBOW (sg=0)\n",
    "    vector_size=100,  # Ukuran vektor fitur\n",
    "    negative=5,  # Jumlah negative sampling\n",
    "    window=2,  # Jarak maksimum antara kata target dan kata-kata yang mengelilinginya\n",
    "    min_count=1,  # Minimum jumlah kemunculan kata untuk dimasukkan ke dalam model\n",
    "    workers=cores,  # Jumlah worker yang akan digunakan\n",
    "    alpha=0.065,  # Learning rate awal\n",
    "    min_alpha=0.065,  # Learning rate minimum\n",
    "    hs=1,  # Menggunakan hierarchical softmax\n",
    ")\n",
    "\n",
    "# Membangun kosakata dari semua komentar yang telah dikonversi menjadi menjadi list token\n",
    "model_ug_cbow.build_vocab(text_tokenize)\n",
    "\n",
    "\"\"\"\n",
    "bagian kode ini berfungsi untuk mempersiapkan dan mengatur model Word2Vec dengan arsitektur Continuous Bag of Words (CBOW). \n",
    "Parameter model diatur sesuai kebutuhan. Kemudian, kosakata dibangun dari semua komentar yang telah dikonversi menjadi list token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 2396458.42it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4788906.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4787761.93it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2401054.29it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4795785.47it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1567694.15it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1589588.63it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1603585.97it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4780905.94it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1611843.89it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4642409.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4788906.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4629534.53it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2379662.14it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4643485.37it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2342923.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4697935.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4754805.58it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2390452.97it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2342101.71it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2357814.96it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1588454.20it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4779765.19it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2396745.14it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394453.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2376556.64it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2376556.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.17 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Melatih model Word2Vec dengan arsitektur CBOW sebanyak 30 epoch \n",
    "for epoch in range(30):\n",
    "    # Mengacak urutan data untuk setiap epoch: membuat variasi dalam data latih untuk setiap epoch\n",
    "    shuffled_data = utils.shuffle(text_tokenize)\n",
    "    \n",
    "    # Melatih model dengan data yang telah diacak: proses pembelajaran model\n",
    "    model_ug_cbow.train(shuffled_data, total_examples=len(text_tokenize), epochs=1)\n",
    "    \n",
    "    # Mengurangi learning rate sebesar 0.002 setiap epoch: untuk mengoptimalkan proses pembelajaran\n",
    "    model_ug_cbow.alpha -= 0.002\n",
    "    \n",
    "    # Menyesuaikan learning rate minimum agar sama dengan learning rate saat ini\n",
    "    model_ug_cbow.min_alpha = model_ug_cbow.alpha\n",
    "\n",
    "\"\"\"\n",
    "bagian kode ini berfungsi untuk melatih model Word2Vec dengan arsitektur CBOW. \n",
    "Pelatihan dilakukan sebanyak 30 epoch, dengan setiap epoch melibatkan pengacakan data dan penurunan learning rate. \n",
    "Ini membantu model untuk belajar dari variasi dalam data dan mengoptimalkan proses pembelajaran \n",
    "dengan mengurangi learning rate seiring berjalannya waktu. \n",
    "Penurunan learning rate ini membantu model untuk konvergen lebih cepat ke solusi optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 4779765.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Membuat model Word2Vec dengan arsitektur Skip-gram\n",
    "model_ug_sg = Word2Vec(\n",
    "    sg=1,  # Menggunakan Skip-gram (sg=1)\n",
    "    vector_size=100,  # Ukuran vektor fitur\n",
    "    negative=5,  # Jumlah negative sampling\n",
    "    window=2,  # Jarak maksimum antara kata target dan kata-kata yang mengelilinginya\n",
    "    min_count=1,  # Minimum jumlah kemunculan kata untuk dimasukkan ke dalam model\n",
    "    workers=cores,  # Jumlah worker yang akan digunakan\n",
    "    alpha=0.065,  # Learning rate awal\n",
    "    min_alpha=0.065,  # Learning rate minimum\n",
    "    hs=1,  # Menggunakan hierarchical softmax\n",
    ")\n",
    "\n",
    "# Membangun kosakata dari semua komentar yang telah dikonversi menjadi  list token\n",
    "model_ug_sg.build_vocab(text_tokenize)\n",
    "\n",
    "\"\"\"\n",
    "bagian kode ini berfungsi untuk mempersiapkan dan mengatur model Word2Vec dengan arsitektur Skip-Gram. \n",
    "Parameter model diatur sesuai kebutuhan. Kemudian, kosakata dibangun dari semua komentar yang telah dikonversi menjadi list token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 1194656.24it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393308.95it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2368408.12it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2342101.71it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2376556.64it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4642409.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393023.04it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2357537.47it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393594.92it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4787761.93it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395885.17it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393594.92it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394167.07it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1596174.97it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395025.81it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1583556.99it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4785474.42it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2381642.60it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2336637.81it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4643485.37it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394739.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2403070.53it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2338274.30it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4640258.49it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394453.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2397031.94it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2399616.18it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393594.92it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394739.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.1 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Melatih model Word2Vec dengan arsitektur Skip-gram sebanyak 30 epoch\n",
    "for epoch in range(30):\n",
    "    # Mengacak urutan data untuk setiap epoch\n",
    "    shuffled_data = utils.shuffle(text_tokenize)\n",
    "    \n",
    "    # Melatih model dengan data yang telah diacak\n",
    "    model_ug_sg.train(shuffled_data, total_examples=len(text_tokenize), epochs=1)\n",
    "    \n",
    "    # Mengurangi learning rate sebesar 0.002 setiap epoch\n",
    "    model_ug_sg.alpha -= 0.002\n",
    "    \n",
    "    # Menyesuaikan learning rate minimum agar sama dengan learning rate saat ini\n",
    "    model_ug_sg.min_alpha = model_ug_sg.alpha\n",
    "    \n",
    "\"\"\"\n",
    "Pelatihan dilakukan sebanyak 30 epoch, dengan setiap epoch melibatkan pengacakan data dan penurunan learning rate. \n",
    "Ini membantu model untuk belajar dari variasi dalam data dan mengoptimalkan proses pembelajaran \n",
    "dengan mengurangi learning rate seiring berjalannya waktu. \n",
    "Penurunan learning rate ini membantu model untuk konvergen lebih cepat ke solusi optimal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan model Word2Vec CBOW yang telah dilatih\n",
    "model_ug_cbow.save('../Model/w2v_model_ug_cbow.word2vec')\n",
    "\n",
    "# Menyimpan model Word2Vec Skip-gram yang telah dilatih\n",
    "model_ug_sg.save('../Model/w2v_model_ug_sg.word2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBOW: memprediksi kata target (focus word) berdasarkan kata-kata konteks yang mengelilinginya. Sebagai contoh, diberikan kalimat \"Kucing itu sangat lucu\", dan kata target adalah \"sangat\", maka CBOW akan menggunakan \"Kucing\", \"itu\", \"lucu\" sebagai konteks untuk memprediksi kata \"sangat\".\n",
    "\n",
    "Skip-gram: mencoba memprediksi kata-kata konteks (kata-kata sekitar) berdasarkan kata target (kata pusat). Sebagai contoh, diberikan kalimat \"Kucing itu sangat lucu\", dan kata target adalah \"sangat\", maka Skip-gram akan menggunakan \"sangat\" untuk memprediksi kata \"Kucing\", \"itu\", dan \"lucu\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemat waktu: Menyimpan model menghindari kebutuhan untuk melatihnya lagi, yang bisa memakan waktu lama.\n",
    "\n",
    "Reproduktibilitas: Model yang disimpan bisa digunakan kembali untuk tujuan yang sama atau berbeda, dan bisa dibagi dengan orang lain, mendukung penelitian dan pengembangan.\n",
    "\n",
    "Pengujian: Model yang disimpan memungkinkan untuk pengujian dan validasi lebih lanjut, memungkinkan perbandingan dan optimalisasi performa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
