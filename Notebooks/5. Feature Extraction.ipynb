{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "from ast import literal_eval\n",
    "\n",
    "# Gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Dataset : 4776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_removal</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_manual_replaced</th>\n",
       "      <th>text_tokenize</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video1</td>\n",
       "      <td>Baiknya bagaimana menurut kalian?</td>\n",
       "      <td>baiknya bagaimana menurut kalian</td>\n",
       "      <td>baik bagaimana turut kalian</td>\n",
       "      <td>baik bagaimana turut kalian</td>\n",
       "      <td>baik bagaimana turut kalian</td>\n",
       "      <td>[baik, bagaimana, turut, kalian]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>video1</td>\n",
       "      <td>Betul dok betul  dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>betul dok betul dok</td>\n",
       "      <td>[betul, dok, betul, dok]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>video1</td>\n",
       "      <td>Betul dok mungkin efek sa di</td>\n",
       "      <td>betul dok mungkin efek sa di</td>\n",
       "      <td>betul dok mungkin efek sa</td>\n",
       "      <td>betul dok mungkin efek sa</td>\n",
       "      <td>betul dok mungkin efek sa</td>\n",
       "      <td>[betul, dok, mungkin, efek, sa]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>video1</td>\n",
       "      <td>Bpom aneh, tidak kerja. Kenapa ko seperti itu.</td>\n",
       "      <td>bpom aneh tidak kerja kenapa ko seperti itu</td>\n",
       "      <td>bpom aneh kerja ko itu</td>\n",
       "      <td>bpom aneh kerja kok itu</td>\n",
       "      <td>bpom aneh kerja kok itu</td>\n",
       "      <td>[bpom, aneh, kerja, kok, itu]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video1</td>\n",
       "      <td>Benar banget anak sy aj hrs sirup minum obatny...</td>\n",
       "      <td>benar banget anak sy aj hrs sirup minum obatny...</td>\n",
       "      <td>benar banget anak sy aj hrs sirup minum obat d...</td>\n",
       "      <td>benar banget anak saya saja harus sirup minum ...</td>\n",
       "      <td>benar banget anak aku saja harus sirup minum o...</td>\n",
       "      <td>[benar, banget, anak, aku, saja, harus, sirup,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id                                       comment_text  \\\n",
       "0   video1                  Baiknya bagaimana menurut kalian?   \n",
       "1   video1                               Betul dok betul  dok   \n",
       "2   video1                       Betul dok mungkin efek sa di   \n",
       "3   video1     Bpom aneh, tidak kerja. Kenapa ko seperti itu.   \n",
       "4   video1  Benar banget anak sy aj hrs sirup minum obatny...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0                   baiknya bagaimana menurut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                       betul dok mungkin efek sa di   \n",
       "3        bpom aneh tidak kerja kenapa ko seperti itu   \n",
       "4  benar banget anak sy aj hrs sirup minum obatny...   \n",
       "\n",
       "                                        text_removal  \\\n",
       "0                        baik bagaimana turut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                          betul dok mungkin efek sa   \n",
       "3                             bpom aneh kerja ko itu   \n",
       "4  benar banget anak sy aj hrs sirup minum obat d...   \n",
       "\n",
       "                                     text_normalized  \\\n",
       "0                        baik bagaimana turut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                          betul dok mungkin efek sa   \n",
       "3                            bpom aneh kerja kok itu   \n",
       "4  benar banget anak saya saja harus sirup minum ...   \n",
       "\n",
       "                                text_manual_replaced  \\\n",
       "0                        baik bagaimana turut kalian   \n",
       "1                                betul dok betul dok   \n",
       "2                          betul dok mungkin efek sa   \n",
       "3                            bpom aneh kerja kok itu   \n",
       "4  benar banget anak aku saja harus sirup minum o...   \n",
       "\n",
       "                                       text_tokenize  label  \n",
       "0                   [baik, bagaimana, turut, kalian]      0  \n",
       "1                           [betul, dok, betul, dok]      0  \n",
       "2                    [betul, dok, mungkin, efek, sa]      0  \n",
       "3                      [bpom, aneh, kerja, kok, itu]     -1  \n",
       "4  [benar, banget, anak, aku, saja, harus, sirup,...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_csv('../Data/4. Labeling/labeling.csv')\n",
    "\n",
    "# Mengonversi kolom tokenisasi menjadi list\n",
    "df['text_tokenize'] = df['text_tokenize'].apply(literal_eval)\n",
    "\n",
    "text_tokenize = df['text_tokenize']\n",
    "\n",
    "# Menampilkan total dataset\n",
    "print(\"Total Dataset :\", len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_comments_ug(comments, label):\n",
    "    \"\"\"\n",
    "    Fungsi ini mengonversi setiap komentar YouTube menjadi objek TaggedDocument \n",
    "    yang terdiri dari kata-kata dalam komentar dan label/tag yang terkait dengan komentar tersebut.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, c in zip(comments.index, comments):\n",
    "        result.append(TaggedDocument(c, [prefix + '_%s' % i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi semua komentar YouTube menjadi objek TaggedDocument\n",
    "all_comments_w2v = labelize_comments_ug(text_tokenize, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec dengan arsitektur Continuous Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 1595412.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Jumlah core CPU yang tersedia\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# Membuat model Word2Vec dengan arsitektur CBOW\n",
    "model_ug_cbow = Word2Vec(\n",
    "    sg=0,  # Menggunakan CBOW (sg=0)\n",
    "    vector_size=100,  # Ukuran vektor fitur\n",
    "    negative=5,  # Jumlah negative sampling\n",
    "    window=2,  # Jarak maksimum antara kata target dan kata-kata yang mengelilinginya\n",
    "    min_count=1,  # Minimum jumlah kemunculan kata untuk dimasukkan ke dalam model\n",
    "    workers=cores,  # Jumlah worker yang akan digunakan\n",
    "    alpha=0.065,  # Learning rate awal\n",
    "    min_alpha=0.065,  # Learning rate minimum\n",
    "    hs=1,  # Menggunakan hierarchical softmax\n",
    ")\n",
    "\n",
    "# Membangun kosakata dari semua komentar yang telah dikonversi menjadi TaggedDocument\n",
    "model_ug_cbow.build_vocab([x.words for x in tqdm(all_comments_w2v)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 2396458.42it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4788906.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4787761.93it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2401054.29it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4795785.47it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1567694.15it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1589588.63it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1603585.97it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4780905.94it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1611843.89it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4642409.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4788906.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4629534.53it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2379662.14it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4643485.37it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2342923.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4697935.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4754805.58it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2390452.97it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2342101.71it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2357814.96it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1588454.20it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4779765.19it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2396745.14it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394453.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2376556.64it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2376556.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.17 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Melatih model Word2Vec dengan arsitektur CBOW sebanyak 10 epoch \n",
    "for epoch in range(30):\n",
    "    # Mengacak urutan data untuk setiap epoch\n",
    "    shuffled_data = utils.shuffle([x.words for x in tqdm(all_comments_w2v)])\n",
    "    \n",
    "    # Melatih model dengan data yang telah diacak\n",
    "    model_ug_cbow.train(shuffled_data, total_examples=len(all_comments_w2v), epochs=1)\n",
    "    \n",
    "    # Mengurangi learning rate sebesar 0.002 setiap epoch\n",
    "    model_ug_cbow.alpha -= 0.002\n",
    "    \n",
    "    # Menyesuaikan learning rate minimum agar sama dengan learning rate saat ini\n",
    "    model_ug_cbow.min_alpha = model_ug_cbow.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 4779765.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Membuat model Word2Vec dengan arsitektur Skip-gram\n",
    "model_ug_sg = Word2Vec(\n",
    "    sg=1,  # Menggunakan Skip-gram (sg=1)\n",
    "    vector_size=100,  # Ukuran vektor fitur\n",
    "    negative=5,  # Jumlah negative sampling\n",
    "    window=2,  # Jarak maksimum antara kata target dan kata-kata yang mengelilinginya\n",
    "    min_count=1,  # Minimum jumlah kemunculan kata untuk dimasukkan ke dalam model\n",
    "    workers=cores,  # Jumlah worker yang akan digunakan\n",
    "    alpha=0.065,  # Learning rate awal\n",
    "    min_alpha=0.065,  # Learning rate minimum\n",
    "    hs=1,  # Menggunakan hierarchical softmax\n",
    ")\n",
    "\n",
    "# Membangun kosakata dari semua komentar yang telah dikonversi menjadi TaggedDocument\n",
    "model_ug_sg.build_vocab([x.words for x in tqdm(all_comments_w2v)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4776/4776 [00:00<00:00, 1194656.24it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393308.95it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2368408.12it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2342101.71it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2376556.64it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4642409.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393023.04it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2357537.47it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393594.92it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4787761.93it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395885.17it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395598.65it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393594.92it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394167.07it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1596174.97it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2395025.81it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 1583556.99it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4785474.42it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2381642.60it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2336637.81it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4643485.37it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394739.50it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2403070.53it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2338274.30it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 4640258.49it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394453.25it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2397031.94it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2399616.18it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2393594.92it/s]\n",
      "100%|██████████| 4776/4776 [00:00<00:00, 2394739.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.1 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Melatih model Word2Vec dengan arsitektur Skip-gram sebanyak 10 epoch\n",
    "for epoch in range(30):\n",
    "    # Mengacak urutan data untuk setiap epoch\n",
    "    shuffled_data = utils.shuffle([x.words for x in tqdm(all_comments_w2v)])\n",
    "    \n",
    "    # Melatih model dengan data yang telah diacak\n",
    "    model_ug_sg.train(shuffled_data, total_examples=len(all_comments_w2v), epochs=1)\n",
    "    \n",
    "    # Mengurangi learning rate sebesar 0.002 setiap epoch\n",
    "    model_ug_sg.alpha -= 0.002\n",
    "    \n",
    "    # Menyesuaikan learning rate minimum agar sama dengan learning rate saat ini\n",
    "    model_ug_sg.min_alpha = model_ug_sg.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan model Word2Vec CBOW yang telah dilatih\n",
    "model_ug_cbow.save('../Model/w2v_model_ug_cbow.word2vec')\n",
    "\n",
    "# Menyimpan model Word2Vec Skip-gram yang telah dilatih\n",
    "model_ug_sg.save('../Model/w2v_model_ug_sg.word2vec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
